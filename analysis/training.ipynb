{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model exploration with PyCaret\n",
    "\n",
    "Try PyCaret to start \n",
    "https://github.com/pycaret/pycaret/blob/master/tutorials/Tutorial%20-%20Regression.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = training_df\n",
    "\n",
    "# import pycaret regression and init setup\n",
    "from pycaret.regression import *\n",
    "s = setup(data, target = 'charges', session_id = 123)\n",
    "\n",
    "# import RegressionExperiment and init the class\n",
    "from pycaret.regression import RegressionExperiment\n",
    "exp = RegressionExperiment()\n",
    "\n",
    "# init setup on exp\n",
    "exp.setup(data, target = 'charges', session_id = 123)\n",
    "\n",
    "# compare baseline models\n",
    "best = compare_models()\n",
    "\n",
    "# compare models using OOP\n",
    "# exp.compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the models and interpret \n",
    "# plot residuals\n",
    "plot_model(best, plot = 'residuals')\n",
    "\n",
    "# plot error\n",
    "plot_model(best, plot = 'error')\n",
    "\n",
    "# plot feature importance\n",
    "plot_model(best, plot = 'feature')\n",
    "\n",
    "evaluate_model(best)\n",
    "\n",
    "# train lightgbm model\n",
    "lightgbm = create_model('lightgbm')\n",
    "\n",
    "# interpret summary model\n",
    "interpret_model(lightgbm, plot = 'summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "holdout_pred = predict_model(best)\n",
    "\n",
    "# show predictions df\n",
    "holdout_pred.head()\n",
    "\n",
    "# copy data and drop charges\n",
    "new_data = data.copy()\n",
    "new_data.drop('charges', axis=1, inplace=True)\n",
    "new_data.head()\n",
    "\n",
    "# predict model on new_data\n",
    "predictions = predict_model(best, data = new_data)\n",
    "predictions.head()\n",
    "\n",
    "\n",
    "# save pipeline\n",
    "save_model(best, 'my_first_pipeline')\n",
    "\n",
    "# load pipeline\n",
    "loaded_best_pipeline = load_model('my_first_pipeline')\n",
    "loaded_best_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensembling \n",
    "\n",
    "# train a dt model with default params\n",
    "dt = create_model('dt')\n",
    "\n",
    "# tune hyperparameters of dt\n",
    "tuned_dt = tune_model(dt)\n",
    "\n",
    "# define tuning grid\n",
    "dt_grid = {'max_depth' : [None, 2, 4, 6, 8, 10, 12]}\n",
    "\n",
    "# tune model with custom grid and metric = MAE\n",
    "tuned_dt = tune_model(dt, custom_grid = dt_grid, optimize = 'MAE')\n",
    "\n",
    "# tune dt using optuna\n",
    "tuned_dt = tune_model(dt, search_library = 'optuna')\n",
    "\n",
    "# ensemble with bagging\n",
    "ensemble_model(dt, method = 'Bagging')\n",
    "\n",
    "# ensemble with boosting\n",
    "ensemble_model(dt, method = 'Boosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # top 3 models based on mae\n",
    "best_mae_models_top3 = compare_models(n_select = 3, sort = 'MAE')\n",
    "\n",
    "# blending models \n",
    "blend_models(best_mae_models_top3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best model based on CV metrics\n",
    "# returns the best model out of all trained models in the current setup based on the optimize parameter\n",
    "automl() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dashboard function\n",
    "dashboard(dt, display_format ='inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalize the model \n",
    "final_best = finalize_model(best)\n",
    "\n",
    "# save model\n",
    "# save_model(best, 'my_first_model')\n",
    "\n",
    "\n",
    "# load model\n",
    "# loaded_from_disk = load_model('my_first_model')\n",
    "# loaded_from_disk\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic models to try \n",
    "* Linear Regression - Use sci-kit learn to implement\n",
    "* Logistic Regression\n",
    "* Support Vector Machines\n",
    "* Basic decision trees\n",
    "* Naive Bayes\n",
    "\n",
    "### XGBoost \n",
    "Tree ensemble model that can handle tabular, numerical, low-dimensional data very well. Fast and scalable, and can be hyperparameter tuned to optimize performance.\n",
    "\n",
    "### ResNet-like architecture\n",
    "Neural network architecture adapted for tabular data, allowing learning from shallow and deep features. Use PyTorch or TensorFlow to implement. Less interpretable. \n",
    "\n",
    "### Transformer \n",
    "Use Transformers with tabular data? \n",
    "\n",
    "### KNN - K Nearest Neighbors\n",
    "Predicts the target variable based on the similarity of the features with the nearest neighbors in the training dataset. Computationally expensive, but can be used for regression and classification."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "* Cross-validation\n",
    "* Classification Accuracy\n",
    "* Confusion Matrix\n",
    "* ROC-AUC Curve\n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fine-tuning\n",
    "* Hyperparameter tuning\n",
    "* Ensembling multiple models together - voting classifier, bagging, boosting, XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Univariate Feature Selection:** This method uses statistical tests like chi-squared tests or ANOVA to evaluate the relationship between each feature and the target variable independently. It ranks the features based on their significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "\n",
    "# # For categorical target using Chi-squared test\n",
    "# selector = SelectKBest(score_func=chi2, k=5)\n",
    "# selector.fit_transform(X, y)\n",
    "\n",
    "# # For continuous target using ANOVA F-value\n",
    "# selector = SelectKBest(score_func=f_classif, k=5)\n",
    "# selector.fit_transform(X, y)\n",
    "\n",
    "# # Get feature importances\n",
    "# scores = selector.scores_\n",
    "# feature_importances = pd.DataFrame({'feature': X.columns, 'importance': scores})\n",
    "# feature_importances = feature_importances.sort_values('importance', ascending=False)\n",
    "# print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other statistical testing \n",
    "# import scipy.stats as stats\n",
    "\n",
    "# # Perform a t-test to compare the means of two groups\n",
    "# t_stat, p_value = stats.ttest_ind(group1, group2)\n",
    "# print(\"T-statistic:\", t_stat, \"P-value:\", p_value)\n",
    "\n",
    "# # Perform a chi-squared test to determine the association between two categorical variables\n",
    "# chi_stat, p_value, dof, ex = stats.chi2_contingency(contingency_table)\n",
    "# print(\"Chi-squared statistic:\", chi_stat, \"P-value:\", p_value)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
